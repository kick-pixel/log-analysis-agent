"""
Agentç¼–æ’å™¨

è´Ÿè´£Agentçš„åˆå§‹åŒ–ã€å·¥å…·è°ƒç”¨å’Œå¯¹è¯ç®¡ç†

ä½œè€…: Log Analysis Team
"""

import os
import yaml
from typing import List, Dict, Optional
from pathlib import Path
from loguru import logger

from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

from src.agent_layer.tools.log_tools import ALL_TOOLS, init_tools
from src.storage_layer.keyword_search import KeywordSearchEngine
from src.storage_layer.vector_search import VectorSearchEngine


class LogAnalysisAgent:
    """æ—¥å¿—åˆ†æAgentç¼–æ’å™¨

    é›†æˆLLMã€å·¥å…·å’Œè®°å¿†ï¼Œæä¾›æ™ºèƒ½æ—¥å¿—åˆ†æèƒ½åŠ›
    """

    def __init__(
        self,
        config_path: str = "./config/config.yaml",
        db_path: str = "./data/logs.db",
        vector_db_path: str = "./data/chroma_db"
    ):
        """åˆå§‹åŒ–Agent

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            db_path: SQLiteæ•°æ®åº“è·¯å¾„
            vector_db_path: ChromaDBè·¯å¾„
        """
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)

        # åˆå§‹åŒ–å­˜å‚¨å¼•æ“
        logger.info("Initializing storage engines...")
        self.keyword_engine = KeywordSearchEngine(db_path=db_path)
        self.vector_engine = VectorSearchEngine(db_path=vector_db_path)

        # å½“å‰ä¼šè¯IDï¼ˆç”¨äºæŸ¥è¯¢æ—¶è¿‡æ»¤ï¼‰
        self.current_session_id = None

        # åˆå§‹åŒ–å·¥å…·
        init_tools(self.keyword_engine, self.vector_engine, self)

        # åˆå§‹åŒ–LLM
        logger.info("Initializing LLM...")
        self.llm = self._init_llm()

        # åˆ›å»ºAgent
        logger.info("Creating agent...")
        self.agent_executor = self._create_agent()

        logger.info("LogAnalysisAgent initialized successfully")

    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„

        Returns:
            é…ç½®å­—å…¸
        """
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"Loaded configuration from {config_path}")
            return config
        except Exception as e:
            logger.warning(f"Failed to load config from {config_path}: {e}")
            logger.info("Using default configuration")
            return {
                'llm': {
                    'model': 'gpt-4o',
                    'temperature': 0.1,
                    'max_tokens': 4000
                },
                'agent': {
                    'max_iterations': 10,
                    'verbose': True
                }
            }

    def _init_llm(self) -> ChatOpenAI:
        """åˆå§‹åŒ–LLM

        Returns:
            LLMå®ä¾‹
        """
        llm_config = self.config.get('llm', {})

        # ä»ç¯å¢ƒå˜é‡è·å–API Key
        api_key = os.getenv('OPENAI_API_KEY')
        base_url = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')
        model = os.getenv('OPENAI_MODEL')
        if not api_key:
            raise ValueError(
                "OPENAI_API_KEY not found in environment variables. "
                "Please set it in .env file or environment."
            )

        return ChatOpenAI(
            model=model or llm_config.get('model', 'gpt-4o'),
            temperature=llm_config.get('temperature', 0.1),
            max_tokens=llm_config.get('max_tokens', 4000),
            api_key=api_key,
            base_url=base_url
        )

    def _create_agent(self):
        """åˆ›å»ºAgentæ‰§è¡Œå™¨

        Returns:
            CompiledStateGraphå®ä¾‹ï¼ˆå¯ç›´æ¥invokeçš„agentï¼‰
        """
        # è·å–System Prompt
        agent_config = self.config.get('agent', {})
        system_prompt = agent_config.get('system_prompt', """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è½¦è½½ç³»ç»Ÿï¼ˆAndroid/Linuxï¼‰æ—¥å¿—åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰15å¹´çš„æ•…éšœæ’æŸ¥ç»éªŒã€‚
ä½ æ“…é•¿åˆ†æAndroid Logcatã€Kernel Logç­‰å¤šç§æ—¥å¿—æ ¼å¼ã€‚

ä½ çš„å·¥ä½œæµç¨‹ï¼š
1. ç†è§£ç”¨æˆ·çš„é—®é¢˜æè¿°ï¼ˆæ•…éšœç°è±¡ã€å‘ç”Ÿæ—¶é—´ï¼‰
2. ä½¿ç”¨å·¥å…·æ£€ç´¢ç›¸å…³æ—¥å¿—ï¼ˆæ—¶é—´èŒƒå›´ã€å…³é”®è¯ã€æ¨¡å—ï¼‰
3. å®šä½å…³é”®é”™è¯¯æ—¥å¿—å’Œå †æ ˆä¿¡æ¯
4. åˆ†æä¸Šä¸‹æ–‡ï¼Œæ¨æ–­æ ¹æœ¬åŸå› 
5. ç»™å‡ºæ¸…æ™°çš„ç»“è®ºå’Œå»ºè®®

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- **æ•…éšœæ—¶é—´ç‚¹**ï¼šç²¾ç¡®åˆ°ç§’
- **å…³é”®æ—¥å¿—**ï¼šå±•ç¤ºæ ¸å¿ƒé”™è¯¯ä¿¡æ¯
- **æ ¹å› åˆ†æ**ï¼šè§£é‡Šä¸ºä»€ä¹ˆå‘ç”Ÿæ•…éšœ
- **å»ºè®®æ–¹æ¡ˆ**ï¼šç»™å‡ºå¯è¡Œçš„ä¿®å¤å»ºè®®

æ³¨æ„ï¼šå¦‚æœæ— æ³•ç¡®å®šæ ¹æœ¬åŸå› ï¼Œè¯·æ˜ç¡®è¯´æ˜ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚
        """.strip())

        # ä½¿ç”¨æ–°çš„create_agent APIï¼ˆè¿”å›CompiledStateGraphï¼‰
        agent = create_agent(
            model=self.llm,
            tools=ALL_TOOLS,
            system_prompt=system_prompt
        )

        return agent

    def analyze(
        self,
        query: str,
        chat_history: Optional[List] = None
    ) -> Dict:
        """åˆ†æç”¨æˆ·æŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            chat_history: å¯¹è¯å†å²ï¼ˆå¯é€‰ï¼‰

        Returns:
            åŒ…å«å›ç­”å’Œä¸­é—´æ­¥éª¤çš„å­—å…¸
        """
        try:
            logger.info(f"Processing query: {query}")

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = chat_history or []
            messages.append(HumanMessage(content=query))

            # æ‰§è¡ŒAgentï¼ˆcreate_agentè¿”å›çš„CompiledStateGraphæ¥å—messagesï¼‰
            result = self.agent_executor.invoke({"messages": messages})

            # æå–æœ€åçš„AIå›å¤
            final_messages = result.get('messages', [])
            answer = ""
            if final_messages:
                for msg in reversed(final_messages):
                    if isinstance(msg, AIMessage) and msg.content:
                        answer = msg.content
                        break

            return {
                'answer': answer,
                'messages': final_messages,
                'success': True
            }

        except Exception as e:
            logger.error(f"Analysis error: {e}", exc_info=True)
            return {
                'answer': f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                'messages': [],
                'success': False,
                'error': str(e)
            }

    def load_logs(
        self,
        log_file_path: str,
        session_id: str = "default"
    ) -> Dict:
        """åŠ è½½æ—¥å¿—æ–‡ä»¶

        Args:
            log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            session_id: ä¼šè¯ID

        Returns:
            åŠ è½½ç»“æœå­—å…¸
        """
        from src.data_layer.parsers.logcat_parser import LogcatParser
        from src.data_layer.preprocessor import LogPreprocessor

        try:
            logger.info(f"Loading log file: {log_file_path}")

            # è§£ææ—¥å¿—
            parser = LogcatParser()
            entries = parser.parse_file(log_file_path)

            if not entries:
                return {
                    'success': False,
                    'message': 'æœªèƒ½è§£æåˆ°æœ‰æ•ˆçš„æ—¥å¿—æ¡ç›®'
                }

            logger.info(f"Parsed {len(entries)} log entries")

            # é¢„å¤„ç†ï¼ˆä¿ç•™æ‰€æœ‰INFOåŠä»¥ä¸Šçº§åˆ«ï¼‰
            preprocessor = LogPreprocessor(
                enable_deduplication=True,
                enable_pii_masking=True,
                min_log_level='I'
            )
            processed_entries = preprocessor.process(entries)

            logger.info(f"Preprocessed to {len(processed_entries)} entries")

            # å­˜å…¥å…³é”®è¯æœç´¢å¼•æ“ï¼ˆç´¢å¼•æ‰€æœ‰æ—¥å¿—ï¼Œå…³é”®è¯æœç´¢å¾ˆå¿«ï¼‰
            self.keyword_engine.insert_logs(
                processed_entries, session_id=session_id)

            # å‘é‡æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–ï¼šåªç´¢å¼•ERRORå’ŒWARNçº§åˆ«æ—¥å¿—
            # åŸå› ï¼š
            # 1. è¯­ä¹‰æœç´¢ä¸»è¦ç”¨äºåˆ†æé—®é¢˜å’Œé”™è¯¯
            # 2. INFO/DEBUGæ—¥å¿—é€šè¿‡å…³é”®è¯æœç´¢å·²è¶³å¤Ÿ
            # 3. å¯å¤§å¹…æå‡å†™å…¥é€Ÿåº¦ï¼ˆå‡å°‘80%æ•°æ®é‡ï¼‰
            important_entries = [
                entry for entry in processed_entries
                if entry.level in ['W', 'E', 'F']  # WARN, ERROR, FATAL
            ]

            logger.info(
                f"Indexing {len(important_entries)} important logs (W/E/F) to vector database...")

            if important_entries:
                self.vector_engine.insert_logs(
                    important_entries, session_id=session_id)
            else:
                logger.warning(
                    "No ERROR/WARN logs found, skipping vector indexing")

            # ç»Ÿè®¡ä¿¡æ¯
            total_logs = len(processed_entries)
            vector_logs = len(important_entries)
            logger.info(
                f"ğŸ“Š å­˜å‚¨ç»Ÿè®¡: å…³é”®è¯ç´¢å¼•={total_logs}, å‘é‡ç´¢å¼•={vector_logs} ({vector_logs/total_logs*100:.1f}%)")

            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self.keyword_engine.get_statistics(session_id=session_id)

            # è®¾ç½®å½“å‰ä¼šè¯IDï¼ˆç”¨äºåç»­æŸ¥è¯¢ï¼‰
            self.current_session_id = session_id
            logger.info(f"âœ… Current session set to: {session_id}")

            return {
                'success': True,
                'message': f'æˆåŠŸåŠ è½½ {len(processed_entries)} æ¡æ—¥å¿—',
                'statistics': stats
            }

        except Exception as e:
            logger.error(f"Failed to load logs: {e}")
            return {
                'success': False,
                'message': f'åŠ è½½æ—¥å¿—å¤±è´¥: {str(e)}',
                'error': str(e)
            }

    def get_statistics(self, session_id: Optional[str] = None) -> Dict:
        """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯

        Args:
            session_id: ä¼šè¯ID

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return self.keyword_engine.get_statistics(session_id=session_id)

    def clear_session(self, session_id: str):
        """æ¸…é™¤ä¼šè¯æ•°æ®

        Args:
            session_id: ä¼šè¯ID
        """
        logger.info(f"Clearing session: {session_id}")
        self.keyword_engine.clear_session(session_id)
        self.vector_engine.clear_session(session_id)


def main():
    """æµ‹è¯•å‡½æ•°"""
    from dotenv import load_dotenv

    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # æ£€æŸ¥API Key
    if not os.getenv('OPENAI_API_KEY'):
        print("\nâš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®OPENAI_API_KEY")
        print("\nè·³è¿‡Agentæµ‹è¯•ï¼Œä»…æµ‹è¯•æ—¥å¿—åŠ è½½åŠŸèƒ½\n")

        # åªæµ‹è¯•æ—¥å¿—åŠ è½½
        from src.storage_layer.keyword_search import KeywordSearchEngine
        keyword_engine = KeywordSearchEngine(db_path="./data/test_logs.db")
        stats = keyword_engine.get_statistics()
        print(f"æ•°æ®åº“ç»Ÿè®¡: {stats}")
        return

    # æµ‹è¯•æ ·æœ¬è·¯å¾„
    sample_path = Path(__file__).parent.parent.parent / \
        "tests" / "sample_logs" / "android_logcat_sample.log"

    # åˆ›å»ºAgent
    print("\n=== åˆå§‹åŒ–Log Analysis Agent ===")
    agent = LogAnalysisAgent(
        db_path="./data/test_agent_logs.db",
        vector_db_path="./data/test_agent_chroma"
    )

    # åŠ è½½æ—¥å¿—
    print("\n=== åŠ è½½æµ‹è¯•æ—¥å¿— ===")
    load_result = agent.load_logs(
        str(sample_path), session_id="test_agent_session")
    print(f"åŠ è½½ç»“æœ: {load_result['message']}")
    if load_result['success']:
        stats = load_result['statistics']
        print(f"æ€»æ—¥å¿—æ•°: {stats['total_count']}")
        print(f"çº§åˆ«åˆ†å¸ƒ: {stats['level_distribution']}")

    # æµ‹è¯•æŸ¥è¯¢
    print("\n=== æµ‹è¯•æŸ¥è¯¢1: æŸ¥æ‰¾å´©æºƒ ===")
    result1 = agent.analyze("æŸ¥æ‰¾æ‰€æœ‰å´©æºƒ(Crash)ç›¸å…³çš„æ—¥å¿—")
    print(f"\nAgentå›ç­”:\n{result1['answer']}\n")

    # æµ‹è¯•æŸ¥è¯¢2
    print("\n=== æµ‹è¯•æŸ¥è¯¢2: åˆ†ææ—¶é—´æ®µ ===")
    result2 = agent.analyze("åˆ†æ14:00åˆ°14:30ä¹‹é—´çš„é”™è¯¯")
    print(f"\nAgentå›ç­”:\n{result2['answer']}\n")


if __name__ == "__main__":
    main()
