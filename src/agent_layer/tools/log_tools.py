"""
æ—¥å¿—åˆ†æAgentå·¥å…·é›†

æä¾›ç»™LLMè°ƒç”¨çš„å·¥å…·å‡½æ•°ï¼Œç”¨äºæŸ¥è¯¢å’Œåˆ†ææ—¥å¿—

ä½œè€…: Log Analysis Team
"""

from typing import Optional, List, Dict, Any
from langchain.tools import tool
from loguru import logger

# å…¨å±€å­˜å‚¨å¼•æ“å®ä¾‹ï¼ˆå°†åœ¨åˆå§‹åŒ–æ—¶è®¾ç½®ï¼‰
_keyword_engine = None
_vector_engine = None
_orchestrator = None


def init_tools(keyword_engine, vector_engine, orchestrator):
    """åˆå§‹åŒ–å·¥å…·ï¼Œæ³¨å…¥å­˜å‚¨å¼•æ“å®ä¾‹
    
    Args:
        keyword_engine: å…³é”®è¯æœç´¢å¼•æ“å®ä¾‹
        vector_engine: å‘é‡æœç´¢å¼•æ“å®ä¾‹
        orchestrator: Agent orchestratorå®ä¾‹ï¼ˆç”¨äºè·å–current_session_idï¼‰
    """
    global _keyword_engine, _vector_engine, _orchestrator
    _keyword_engine = keyword_engine
    _vector_engine = vector_engine
    _orchestrator = orchestrator
    logger.info("Agent tools initialized with storage engines")


@tool
def query_logs_by_time_range(
    start_time: str,
    end_time: str,
    level: Optional[str] = None
) -> str:
    """æ ¹æ®æ—¶é—´èŒƒå›´æŸ¥è¯¢æ—¥å¿—
    
    ç”¨äºæŸ¥çœ‹ç‰¹å®šæ—¶é—´æ®µå†…çš„æ—¥å¿—è®°å½•ã€‚
    
    Args:
        start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼Œå¦‚"2025-11-26T14:28:00"ï¼‰
        end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        level: å¯é€‰çš„æ—¥å¿—çº§åˆ«è¿‡æ»¤ï¼ˆI/W/E/Fï¼‰
        
    Returns:
        æŸ¥è¯¢ç»“æœçš„æè¿°æ€§æ–‡æœ¬
    """
    if not _keyword_engine:
        return "é”™è¯¯ï¼šæœç´¢å¼•æ“æœªåˆå§‹åŒ–"
    
    try:
        # è·å–å½“å‰ä¼šè¯ID
        session_id = _orchestrator.current_session_id if _orchestrator else None
        logger.info(f"ğŸ” query_logs_by_time_range - session_id: {session_id}")
        
        results = _keyword_engine.get_logs_by_time_range(
            start_time=start_time,
            end_time=end_time,
            level=level,
            session_id=session_id,
            limit=50
        )
        
        if not results:
            return f"åœ¨æ—¶é—´èŒƒå›´ {start_time} åˆ° {end_time} å†…æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—"
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = [f"æ‰¾åˆ° {len(results)} æ¡æ—¥å¿—ï¼š\n"]
        
        # æŒ‰çº§åˆ«ç»Ÿè®¡
        level_count = {}
        for log in results:
            lv = log.get('level', 'Unknown')
            level_count[lv] = level_count.get(lv, 0) + 1
        
        output.append(f"çº§åˆ«åˆ†å¸ƒ: {dict(level_count)}\n")
        output.append("\nå‰10æ¡æ—¥å¿—ï¼š\n")
        
        for i, log in enumerate(results[:10], 1):
            timestamp = log.get('timestamp', 'N/A')
            lv = log.get('level', '?')
            tag = log.get('tag', 'Unknown')
            msg = log.get('message', '')[:100]  # é™åˆ¶æ¶ˆæ¯é•¿åº¦
            output.append(f"{i}. [{timestamp}] {lv}/{tag}: {msg}\n")
        
        if len(results) > 10:
            output.append(f"\n...è¿˜æœ‰ {len(results) - 10} æ¡æ—¥å¿—æœªæ˜¾ç¤º\n")
        
        return ''.join(output)
        
    except Exception as e:
        logger.error(f"query_logs_by_time_range error: {e}")
        return f"æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool
def search_error_keywords(
    keywords: str,
    level: Optional[str] = None,
    tag: Optional[str] = None
) -> str:
    """æœç´¢åŒ…å«ç‰¹å®šå…³é”®è¯çš„é”™è¯¯æ—¥å¿—
    
    ç”¨äºæŸ¥æ‰¾åŒ…å«ç‰¹å®šå…³é”®è¯ï¼ˆå¦‚"crash"ã€"exception"ã€"error"ï¼‰çš„æ—¥å¿—ã€‚
    
    Args:
        keywords: æœç´¢å…³é”®è¯ï¼ˆæ”¯æŒå¤šä¸ªè¯ï¼Œç”¨ç©ºæ ¼åˆ†éš”ï¼›æ”¯æŒORé€»è¾‘ï¼‰
        level: å¯é€‰çš„æ—¥å¿—çº§åˆ«è¿‡æ»¤ï¼ˆEè¡¨ç¤ºErrorï¼ŒFè¡¨ç¤ºFatalï¼‰
        tag: å¯é€‰çš„æ¨¡å—Tagè¿‡æ»¤
        
    Returns:
        æœç´¢ç»“æœçš„æè¿°æ€§æ–‡æœ¬
    """
    if not _keyword_engine:
        return "é”™è¯¯ï¼šæœç´¢å¼•æ“æœªåˆå§‹åŒ–"
    
    try:
        # è·å–å½“å‰ä¼šè¯ID
        session_id = _orchestrator.current_session_id if _orchestrator else None
        logger.info(f"ğŸ” search_error_keywords - session_id: {session_id}, keywords: {keywords}")
        
        results = _keyword_engine.search_keywords(
            keywords=keywords,
            level=level,
            tag=tag,
            session_id=session_id,
            limit=30
        )
        
        if not results:
            return f"æ²¡æœ‰æ‰¾åˆ°åŒ…å« '{keywords}' çš„æ—¥å¿—"
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = [f"æ‰¾åˆ° {len(results)} æ¡åŒ¹é…æ—¥å¿—ï¼š\n"]
        
        # æŒ‰Tagç»Ÿè®¡
        tag_count = {}
        for log in results:
            t = log.get('tag', 'Unknown')
            tag_count[t] = tag_count.get(t, 0) + 1
        
        # æ˜¾ç¤ºTop 5 Tags
        top_tags = sorted(tag_count.items(), key=lambda x: x[1], reverse=True)[:5]
        output.append(f"ä¸»è¦æ¨¡å—: {dict(top_tags)}\n")
        output.append("\næ—¥å¿—è¯¦æƒ…ï¼š\n")
        
        for i, log in enumerate(results[:15], 1):  # æ˜¾ç¤ºå‰15æ¡
            timestamp = log.get('timestamp', 'N/A')
            lv = log.get('level', '?')
            tag = log.get('tag', 'Unknown')
            msg = log.get('message', '')[:120]
            output.append(f"{i}. [{timestamp}] {lv}/{tag}:\n   {msg}\n")
        
        if len(results) > 15:
            output.append(f"\n...è¿˜æœ‰ {len(results) - 15} æ¡åŒ¹é…æ—¥å¿—\n")
        
        return ''.join(output)
        
    except Exception as e:
        logger.error(f"search_error_keywords error: {e}")
        return f"æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool
def semantic_search_logs(query: str, n_results: int = 10) -> str:
    """ä½¿ç”¨è‡ªç„¶è¯­è¨€è¯­ä¹‰æœç´¢æ—¥å¿—
    
    å½“ç”¨æˆ·çš„æè¿°ä¸å¤Ÿç²¾ç¡®ï¼Œæˆ–è€…éœ€è¦æ¨¡ç³ŠåŒ¹é…æ—¶ä½¿ç”¨ã€‚
    ä¾‹å¦‚ï¼š"ä¸ºä»€ä¹ˆç›¸æœºæ‰“ä¸å¼€"ã€"å†…å­˜ç›¸å…³çš„é—®é¢˜"ç­‰ã€‚
    
    Args:
        query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢æè¿°
        n_results: è¿”å›ç»“æœæ•°é‡ï¼ˆé»˜è®¤10ï¼‰
        
    Returns:
        æœç´¢ç»“æœçš„æè¿°æ€§æ–‡æœ¬
    """
    if not _vector_engine:
        return "é”™è¯¯ï¼šå‘é‡æœç´¢å¼•æ“æœªåˆå§‹åŒ–"
    
    try:
        # è·å–å½“å‰ä¼šè¯ID
        session_id = _orchestrator.current_session_id if _orchestrator else None
        logger.info(f"ğŸ” semantic_search_logs - session_id: {session_id}, query: {query}")
        
        results = _vector_engine.semantic_search(
            query=query,
            n_results=n_results,
            session_id=session_id
        )
        
        if not results:
            return f"æ²¡æœ‰æ‰¾åˆ°ä¸ '{query}' ç›¸å…³çš„æ—¥å¿—"
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = [f"æ‰¾åˆ° {len(results)} æ¡è¯­ä¹‰ç›¸å…³çš„æ—¥å¿—ï¼š\n"]
        output.append(f"ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œè·ç¦»è¶Šå°è¶Šç›¸ä¼¼ï¼‰\n\n")
        
        for i, result in enumerate(results, 1):
            metadata = result.get('metadata', {})
            timestamp = metadata.get('timestamp', 'N/A')
            level = metadata.get('level', '?')
            tag = metadata.get('tag', 'Unknown')
            doc = result.get('document', '')
            distance = result.get('distance', 0)
            
            output.append(f"{i}. [{timestamp}] {level}/{tag}\n")
            output.append(f"   {doc}\n")
            output.append(f"   [ç›¸ä¼¼åº¦è·ç¦»: {distance:.4f}]\n\n")
        
        return ''.join(output)
        
    except Exception as e:
        logger.error(f"semantic_search_logs error: {e}")
        return f"è¯­ä¹‰æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool
def filter_logs_by_tag(tag: str, limit: int = 20) -> str:
    """æŒ‰æ¨¡å—Tagè¿‡æ»¤æ—¥å¿—
    
    ç”¨äºæŸ¥çœ‹ç‰¹å®šæ¨¡å—ï¼ˆå¦‚CameraServiceã€SystemUIç­‰ï¼‰çš„æ‰€æœ‰æ—¥å¿—ã€‚
    
    Args:
        tag: æ¨¡å—Tagåç§°ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
        
    Returns:
        è¿‡æ»¤ç»“æœçš„æè¿°æ€§æ–‡æœ¬
    """
    if not _keyword_engine:
        return "é”™è¯¯ï¼šæœç´¢å¼•æ“æœªåˆå§‹åŒ–"
    
    try:
        # è·å–å½“å‰ä¼šè¯ID
        session_id = _orchestrator.current_session_id if _orchestrator else None
        logger.info(f"ğŸ” filter_logs_by_tag - session_id: {session_id}, tag: {tag}")
        
        results = _keyword_engine.filter_by_tag(tag=tag, session_id=session_id, limit=limit)
        
        if not results:
            return f"æ²¡æœ‰æ‰¾åˆ°TagåŒ…å« '{tag}' çš„æ—¥å¿—"
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = [f"æ‰¾åˆ° {len(results)} æ¡ '{tag}' ç›¸å…³æ—¥å¿—ï¼š\n"]
        
        # ç»Ÿè®¡çº§åˆ«åˆ†å¸ƒ
        level_count = {}
        for log in results:
            lv = log.get('level', 'Unknown')
            level_count[lv] = level_count.get(lv, 0) + 1
        
        output.append(f"çº§åˆ«åˆ†å¸ƒ: {dict(level_count)}\n\n")
        
        for i, log in enumerate(results, 1):
            timestamp = log.get('timestamp', 'N/A')
            lv = log.get('level', '?')
            full_tag = log.get('tag', 'Unknown')
            msg = log.get('message', '')[:100]
            output.append(f"{i}. [{timestamp}] {lv}/{full_tag}:\n   {msg}\n")
        
        return ''.join(output)
        
    except Exception as e:
        logger.error(f"filter_logs_by_tag error: {e}")
        return f"è¿‡æ»¤æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool
def get_log_context(log_id: int, window_size: int = 20) -> str:
    """è·å–æŸæ¡æ—¥å¿—çš„ä¸Šä¸‹æ–‡
    
    ç”¨äºæŸ¥çœ‹æŸæ¡å…³é”®æ—¥å¿—å‰åå‘ç”Ÿäº†ä»€ä¹ˆï¼Œå¸®åŠ©ç†è§£æ•…éšœçš„å› æœå…³ç³»ã€‚
    
    Args:
        log_id: æ—¥å¿—IDï¼ˆä»æœç´¢ç»“æœä¸­è·å–ï¼‰
        window_size: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå‰åå„Nè¡Œï¼‰
        
    Returns:
        ä¸Šä¸‹æ–‡æ—¥å¿—çš„æè¿°æ€§æ–‡æœ¬
    """
    if not _keyword_engine:
        return "é”™è¯¯ï¼šæœç´¢å¼•æ“æœªåˆå§‹åŒ–"
    
    try:
        results = _keyword_engine.get_context(
            log_id=log_id,
            window_size=window_size
        )
        
        if not results:
            return f"æœªæ‰¾åˆ°æ—¥å¿—ID {log_id} æˆ–æ— ä¸Šä¸‹æ–‡"
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = [f"æ—¥å¿—ID {log_id} çš„ä¸Šä¸‹æ–‡ï¼ˆå‰å{window_size}è¡Œï¼‰ï¼š\n\n"]
        
        for log in results:
            timestamp = log.get('timestamp', 'N/A')
            lv = log.get('level', '?')
            tag = log.get('tag', 'Unknown')
            msg = log.get('message', '')
            
            # æ ‡è®°ç›®æ ‡æ—¥å¿—
            marker = " >>> " if log.get('id') == log_id else "     "
            
            output.append(f"{marker}[{timestamp}] {lv}/{tag}:\n")
            output.append(f"{marker}  {msg}\n\n")
        
        return ''.join(output)
        
    except Exception as e:
        logger.error(f"get_log_context error: {e}")
        return f"è·å–ä¸Šä¸‹æ–‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool
def get_error_statistics(session_id: Optional[str] = None) -> str:
    """è·å–é”™è¯¯ç»Ÿè®¡ä¿¡æ¯
    
    ç”¨äºäº†è§£æ•´ä½“æ—¥å¿—çš„é”™è¯¯åˆ†å¸ƒæƒ…å†µã€‚
    
    Args:
        session_id: å¯é€‰çš„ä¼šè¯IDï¼Œä¸æŒ‡å®šåˆ™ç»Ÿè®¡å…¨éƒ¨
        
    Returns:
        ç»Ÿè®¡ä¿¡æ¯çš„æè¿°æ€§æ–‡æœ¬
    """
    if not _keyword_engine:
        return "é”™è¯¯ï¼šæœç´¢å¼•æ“æœªåˆå§‹åŒ–"
    
    try:
        stats = _keyword_engine.get_statistics(session_id=session_id)
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = ["=== æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯ ===\n\n"]
        
        output.append(f"æ€»æ—¥å¿—æ•°: {stats.get('total_count', 0)}\n\n")
        
        output.append("æ—¥å¿—çº§åˆ«åˆ†å¸ƒ:\n")
        level_dist = stats.get('level_distribution', {})
        for level, count in sorted(level_dist.items()):
            percentage = (count / stats.get('total_count', 1)) * 100
            output.append(f"  {level}: {count} ({percentage:.1f}%)\n")
        
        output.append("\nTop 10 æ¨¡å—ï¼ˆæŒ‰æ—¥å¿—æ•°é‡ï¼‰:\n")
        top_tags = stats.get('top_tags', {})
        for i, (tag, count) in enumerate(top_tags.items(), 1):
            output.append(f"  {i}. {tag}: {count}\n")
        
        time_range = stats.get('time_range', {})
        if time_range.get('start') and time_range.get('end'):
            output.append(f"\næ—¶é—´èŒƒå›´:\n")
            output.append(f"  å¼€å§‹: {time_range['start']}\n")
            output.append(f"  ç»“æŸ: {time_range['end']}\n")
        
        return ''.join(output)
        
    except Exception as e:
        logger.error(f"get_error_statistics error: {e}")
        return f"è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


# å¯¼å‡ºæ‰€æœ‰å·¥å…·
ALL_TOOLS = [
    query_logs_by_time_range,
    search_error_keywords,
    semantic_search_logs,
    filter_logs_by_tag,
    get_log_context,
    get_error_statistics
]


def get_tool_descriptions() -> List[str]:
    """è·å–æ‰€æœ‰å·¥å…·çš„æè¿°
    
    Returns:
        å·¥å…·æè¿°åˆ—è¡¨
    """
    descriptions = []
    for tool_func in ALL_TOOLS:
        descriptions.append(f"- {tool_func.name}: {tool_func.description}")
    return descriptions

